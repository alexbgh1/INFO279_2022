{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación Matriz de confusión y Kappa de Cohen\n",
    "<p>Esta es una implementación para el tipo de dataset almacenado en data_1.csv o data_2.csv. La estructura es la siguiente:</p>\n",
    "<ul>\n",
    "<li><b>id_news:</b> ID de una noticia.</li>\n",
    "<li><b>title:</b> Titulo de la noticia.</li>\n",
    "<li><b>label:</b> El titulo es [POS, NEU, NEG]: positivo, neutral, negativo.</li>\n",
    "<li><b>anotador:</b> Inicial del etiquetador y primer apellido.</li>\n",
    "<li><b>label_ministerio:</b> Ministerio al que corresponde el titulo, abajo se ven los ministerios considerados.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Para procesar los archivos de manera correcta los archivos deben tener las <b>columnas mencionadas</b>, con énfasis en <b>label</b> y <b>label_ministerio</b>, también deben tener las <b>mismas noticias etiquetadas</b>, así como un <b>anotador distinto</b>.</p>\n",
    "<p>Se calculará y retornará la matriz de confusión y coheficiente de Cohen. <strong>Los cálculos son específicos para este tipo de dataset.</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data.csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kohonen_(archivo_1, archivo_2, task):\n",
    "    '''\n",
    "    archivo_1.csv -> id_news, title, label, anotador, label_ministerio\n",
    "    archivo_2.csv -> id_news, title, label, anotador, label_ministerio\n",
    "    task -> 'label' or 'label_ministerio'\n",
    "\n",
    "    Return:\n",
    "    confusion_matrix -> np.array\n",
    "    kappa -> float\n",
    "\n",
    "    Se espera que anotador, label y label_ministerio sean distintos\n",
    "    '''\n",
    "    label = ['POS', 'NEU', 'NEG']\n",
    "    label_ministerio = [\n",
    "        'interior_y_seguridad_publica',\n",
    "        'hacienda',\n",
    "        'economia_fomento_turismo',\n",
    "        'justicia_derechos_humanos',\n",
    "        'salud',\n",
    "        'mineria',\n",
    "        'energia',\n",
    "        'mujer_equidad_genero',\n",
    "        'relaciones_exteriores',\n",
    "        'secreteria_general_presidencia',\n",
    "        'desarrollo_social_familia',\n",
    "        'trabajo_prevision_social',\n",
    "        'vivienda_urbanismo',\n",
    "        'transportes_telecomunicaciones',\n",
    "        'medio_ambiente',\n",
    "        'culturas_artes_patrimonio',\n",
    "        'defensa_nacional',\n",
    "        'educacion',\n",
    "        'obras_publicas',\n",
    "        'agricultura',\n",
    "        'bienes_nacionales',\n",
    "        'deporte',\n",
    "        'ciencia_tecnologia_conocimiento',\n",
    "        'sin_etiqueta'\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Intentamos leer los datos\n",
    "    try:\n",
    "        archivo_1 = pd.read_csv(archivo_1, sep=';')\n",
    "        archivo_2 = pd.read_csv(archivo_2, sep=';')\n",
    "    except:\n",
    "        print('Error Archivo: No se encontró el archivo')\n",
    "        return None\n",
    "    print('OK: Archivos encontrados')\n",
    "    \n",
    "    # La variable 'task' corresponde a la columna que se quiere analizar?\n",
    "    if (task != 'label' and task != 'label_ministerio'):\n",
    "        print(f'Error Task: \"{task}\" no existe')\n",
    "        return None\n",
    "\n",
    "    print(f'OK: Etiqueta válida. Task: {task}')\n",
    "    # Estamos analizando las mismas noticias?\n",
    "    if (archivo_1['id_news'].values == archivo_2['id_news'].values).all():\n",
    "        print('OK: Los archivos tienen las mismas noticias')\n",
    "        \n",
    "        # Mezclamos archivo_1 y archivo_2\n",
    "        # Dejando: title, task, anotador_x\n",
    "        archivo_1 = archivo_1[['title', task, 'anotador']]\n",
    "        archivo_2 = archivo_2[['title', task, 'anotador']]\n",
    "        archivo_1.rename(columns ={'title':'title',task:f'{task}_1','anotador':'anotador_1' }, inplace=True)\n",
    "        archivo_2.rename(columns ={'title':'title',task:f'{task}_2','anotador':'anotador_2' }, inplace=True)\n",
    "        \n",
    "        # df: title\tlabel_1\tanotador_1\tlabel_2\tanotador_2\n",
    "        # o bien df: title label_ministerio_1 anotador_1 label_ministerio_2 anotador_2\n",
    "        df = archivo_1.merge(archivo_2, on='title')\n",
    "        display(df.head())\n",
    "\n",
    "        # --- En este punto ya tenemos label_1 y label_2 ---\n",
    "        real = df[f'{task}_1'].values\n",
    "        pred = df[f'{task}_2'].values\n",
    "\n",
    "        if(task == 'label'):\n",
    "            print(f'OK: Las etiquetas serán -> {label} -> {np.arange(len(label))}')\n",
    "\n",
    "            # Consideraremos que el anotador 1 es el que tiene la etiqueta correcta\n",
    "            # Por lo que si el anotador 1 y el anotador 2 tienen la misma etiqueta\n",
    "            # entonces no hay discrepancia\n",
    "            confusion_matrix = np.zeros((len(label), len(label)))\n",
    "            for i in range(len(label)):\n",
    "                for j in range(len(label)):\n",
    "                    confusion_matrix[i, j] = np.sum((real == label[i]) & (pred == label[j]))\n",
    "            print(f'\\nExito (1/2): Retornando Matriz de Confusión')\n",
    "            print(confusion_matrix)\n",
    "            \n",
    "            # Calculamos P0 de Kappa\n",
    "            # P0 = Suma de aciertos (diagonal) dividido total\n",
    "            suma_aciertos = np.sum(np.diag(confusion_matrix))\n",
    "            total = np.sum(confusion_matrix)\n",
    "            p0 = suma_aciertos / total\n",
    "\n",
    "            # Calculamos Pe de Kappa\n",
    "            # Pe = Suma de probabilidades\n",
    "            # ej: pe_1= Sumar (fila i=0)/(total) * (Sumar columna i=0)/(total)\n",
    "            # ej: pe_2= Sumar (fila i=1)/(total) * (Sumar columna i=1)/(total)\n",
    "            # ej: pe_3= Sumar (fila i=1)/(total) * (Sumar columna i=1)/(total)\n",
    "            # Valor Pe final: pe_1 + pe_2 + pe_3\n",
    "            pe = 0\n",
    "            for i in range(len(label)):\n",
    "                pe += (np.sum(confusion_matrix[i, :]) / total) * (np.sum(confusion_matrix[:, i]) / total)\n",
    "\n",
    "            # Calculamos Kappa\n",
    "            kappa = (p0 - pe) / (1 - pe)\n",
    "            print(f'\\nExito (2/2): Retornando Kappa')\n",
    "            print(kappa)\n",
    "            return confusion_matrix, kappa\n",
    "\n",
    "\n",
    "        if(task == 'label_ministerio'):\n",
    "            print(f'OK: Las etiquetas serán -> ')\n",
    "            for etiqueta in range(len(label_ministerio)):\n",
    "                print(f'{etiqueta} -> {label_ministerio[etiqueta]}')\n",
    "\n",
    "            confusion_matrix = np.zeros((len(label_ministerio), len(label_ministerio)))\n",
    "            for i in range(len(label_ministerio)):\n",
    "                for j in range(len(label_ministerio)):\n",
    "                    confusion_matrix[i, j] = np.sum((real == label_ministerio[i]) & (pred == label_ministerio[j]))\n",
    "            print(f'\\nExito (1/2): Retornando Matriz de Confusión')\n",
    "            print(confusion_matrix)\n",
    "             \n",
    "            # Calculamos P0 de Kappa\n",
    "            # P0 = Suma de aciertos (diagonal) dividido total\n",
    "            suma_aciertos = np.sum(np.diag(confusion_matrix))\n",
    "            total = np.sum(confusion_matrix)\n",
    "            p0 = suma_aciertos / total\n",
    "\n",
    "            # Calculamos Pe de Kappa\n",
    "            pe = 0\n",
    "            for i in range(len(label_ministerio)):\n",
    "                pe += (np.sum(confusion_matrix[i, :]) / total) * (np.sum(confusion_matrix[:, i]) / total)\n",
    "\n",
    "            # Calculamos Kappa\n",
    "            kappa = (p0 - pe) / (1 - pe)\n",
    "            print(f'\\nExito (2/2): Retornando Kappa')\n",
    "            print(kappa)\n",
    "            return confusion_matrix, kappa\n",
    "        \n",
    "        print('Error: Es posible que algo inesperado haya ocurrido.')\n",
    "        return None\n",
    "    else:\n",
    "        print('Error Archivo: Los archivos tienen noticias diferentes')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: Archivos encontrados\n",
      "OK: Etiqueta válida. Task: label\n",
      "OK: Los archivos tienen las mismas noticias\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_1</th>\n",
       "      <th>anotador_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>anotador_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diputados UDI piden información a  municipalid...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>agarnica</td>\n",
       "      <td>NEU</td>\n",
       "      <td>fruiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Panquehue implementa aplicación lectora de pat...</td>\n",
       "      <td>POS</td>\n",
       "      <td>agarnica</td>\n",
       "      <td>NEU</td>\n",
       "      <td>fruiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dos personas fallecidas dejó accidente de trán...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>agarnica</td>\n",
       "      <td>NEG</td>\n",
       "      <td>fruiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nuevo ataque incendiario dejó un camión destru...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>agarnica</td>\n",
       "      <td>NEG</td>\n",
       "      <td>fruiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PDi detuvo a 4 personas por tráfico en Laguna ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>agarnica</td>\n",
       "      <td>POS</td>\n",
       "      <td>fruiz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title label_1 anotador_1  \\\n",
       "0  Diputados UDI piden información a  municipalid...     NEU   agarnica   \n",
       "1  Panquehue implementa aplicación lectora de pat...     POS   agarnica   \n",
       "2  Dos personas fallecidas dejó accidente de trán...     NEG   agarnica   \n",
       "3  Nuevo ataque incendiario dejó un camión destru...     NEG   agarnica   \n",
       "4  PDi detuvo a 4 personas por tráfico en Laguna ...     POS   agarnica   \n",
       "\n",
       "  label_2 anotador_2  \n",
       "0     NEU      fruiz  \n",
       "1     NEU      fruiz  \n",
       "2     NEG      fruiz  \n",
       "3     NEG      fruiz  \n",
       "4     POS      fruiz  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: Las etiquetas serán -> ['POS', 'NEU', 'NEG'] -> [0 1 2]\n",
      "\n",
      "Exito (1/2): Retornando Matriz de Confusión\n",
      "[[14. 10.  0.]\n",
      " [ 2.  8.  0.]\n",
      " [ 0.  5. 10.]]\n",
      "\n",
      "Exito (2/2): Retornando Kappa\n",
      "0.4911423335369578\n"
     ]
    }
   ],
   "source": [
    "nombre_archivo_1 = 'data_1.csv'\n",
    "nombre_archivo_2 = 'data_2.csv'\n",
    "confusion_matrix, kappa = Kohonen_(nombre_archivo_1, nombre_archivo_2, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: Archivos encontrados\n",
      "OK: Etiqueta válida. Task: label_ministerio\n",
      "OK: Los archivos tienen las mismas noticias\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_ministerio_1</th>\n",
       "      <th>anotador_1</th>\n",
       "      <th>label_ministerio_2</th>\n",
       "      <th>anotador_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diputados UDI piden información a  municipalid...</td>\n",
       "      <td>mujer_equidad_genero</td>\n",
       "      <td>agarnica</td>\n",
       "      <td>mujer_equidad_genero</td>\n",
       "      <td>fruiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Panquehue implementa aplicación lectora de pat...</td>\n",
       "      <td>transportes_telecomunicaciones</td>\n",
       "      <td>agarnica</td>\n",
       "      <td>transportes_telecomunicaciones</td>\n",
       "      <td>fruiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dos personas fallecidas dejó accidente de trán...</td>\n",
       "      <td>transportes_telecomunicaciones</td>\n",
       "      <td>agarnica</td>\n",
       "      <td>transportes_telecomunicaciones</td>\n",
       "      <td>fruiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nuevo ataque incendiario dejó un camión destru...</td>\n",
       "      <td>interior_y_seguridad_publica</td>\n",
       "      <td>agarnica</td>\n",
       "      <td>interior_y_seguridad_publica</td>\n",
       "      <td>fruiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PDi detuvo a 4 personas por tráfico en Laguna ...</td>\n",
       "      <td>interior_y_seguridad_publica</td>\n",
       "      <td>agarnica</td>\n",
       "      <td>interior_y_seguridad_publica</td>\n",
       "      <td>fruiz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Diputados UDI piden información a  municipalid...   \n",
       "1  Panquehue implementa aplicación lectora de pat...   \n",
       "2  Dos personas fallecidas dejó accidente de trán...   \n",
       "3  Nuevo ataque incendiario dejó un camión destru...   \n",
       "4  PDi detuvo a 4 personas por tráfico en Laguna ...   \n",
       "\n",
       "               label_ministerio_1 anotador_1              label_ministerio_2  \\\n",
       "0            mujer_equidad_genero   agarnica            mujer_equidad_genero   \n",
       "1  transportes_telecomunicaciones   agarnica  transportes_telecomunicaciones   \n",
       "2  transportes_telecomunicaciones   agarnica  transportes_telecomunicaciones   \n",
       "3    interior_y_seguridad_publica   agarnica    interior_y_seguridad_publica   \n",
       "4    interior_y_seguridad_publica   agarnica    interior_y_seguridad_publica   \n",
       "\n",
       "  anotador_2  \n",
       "0      fruiz  \n",
       "1      fruiz  \n",
       "2      fruiz  \n",
       "3      fruiz  \n",
       "4      fruiz  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: Las etiquetas serán -> \n",
      "0 -> interior_y_seguridad_publica\n",
      "1 -> hacienda\n",
      "2 -> economia_fomento_turismo\n",
      "3 -> justicia_derechos_humanos\n",
      "4 -> salud\n",
      "5 -> mineria\n",
      "6 -> energia\n",
      "7 -> mujer_equidad_genero\n",
      "8 -> relaciones_exteriores\n",
      "9 -> secreteria_general_presidencia\n",
      "10 -> desarrollo_social_familia\n",
      "11 -> trabajo_prevision_social\n",
      "12 -> vivienda_urbanismo\n",
      "13 -> transportes_telecomunicaciones\n",
      "14 -> medio_ambiente\n",
      "15 -> culturas_artes_patrimonio\n",
      "16 -> defensa_nacional\n",
      "17 -> educacion\n",
      "18 -> obras_publicas\n",
      "19 -> agricultura\n",
      "20 -> bienes_nacionales\n",
      "21 -> deporte\n",
      "22 -> ciencia_tecnologia_conocimiento\n",
      "23 -> sin_etiqueta\n",
      "\n",
      "Exito (1/2): Retornando Matriz de Confusión\n",
      "[[11.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "   0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  2.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "   0.  0.  0.  0.  0.  8.]]\n",
      "\n",
      "Exito (2/2): Retornando Kappa\n",
      "0.7534102833158447\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix, kappa = Kohonen_(nombre_archivo_1, nombre_archivo_2, 'label_ministerio')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fff480b818351191bd10b139918affcc268b35a4173b95bc67c9e000e77644a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
