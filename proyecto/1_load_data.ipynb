{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto (obtención dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- General ---\n",
    "import os\n",
    "\n",
    "# --- Data ---\n",
    "import pandas as pd\n",
    "# from pandasql import sqldf\n",
    "# import numpy as np\n",
    "# import statistics as stats\n",
    "\n",
    "# --- Conexión ---\n",
    "import elasticsearch\n",
    "\n",
    "# --- Procesamiento lenguaje: spacy ---\n",
    "import spacy\n",
    "# from spacy.matcher import Matcher\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# --- Procesamiento lenguaje: gensim ---\n",
    "# import gensim\n",
    "# import gensim.corpora as corpora\n",
    "# from gensim.models import CoherenceModel\n",
    "\n",
    "# --- Prediccion Positividad: POS, NEU, NEG ---\n",
    "# from tqdm import tqdm\n",
    "# import transformers\n",
    "# from transformers import pipeline\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# --- Visualización ---\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim_models \n",
    "# import matplotlib.colors as colors\n",
    "# import matplotlib.pyplot as plt\n",
    "# import geopandas as gpd\n",
    "# %matplotlib inline\n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Configuración ---\n",
    "# User password\n",
    "password = os.environ.get('SOPHIA2')\n",
    "\n",
    "# - - - geoData - - -\n",
    "import tools_region as tr\n",
    "\n",
    "# --- Funciones ---\n",
    "# Cargar paquete de español mediano\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilización de regiones y comunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region encontrada\n"
     ]
    }
   ],
   "source": [
    "data_regiones_comunas = tr.search_region('Región_de_Los_Lagos')\n",
    "if(data_regiones_comunas):\n",
    "    region = data_regiones_comunas['region']\n",
    "    comunas_sql = data_regiones_comunas['comunas']\n",
    "    comunas = [comuna.replace('_', ' ') for comuna in comunas_sql]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización peticiones Sophia2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- [Parametros de búsqueda] ---\n",
    "# -- Nombre archivo --\n",
    "nombre_archivo = 'data_Region_X' # Resultado: ./data/{nombre_archivo}_{from_}_{to_}.csv\n",
    "\n",
    "# -- Parameters queries --\n",
    "# País\n",
    "country=\"chile\"\n",
    "# Fecha\n",
    "from_=\"2022-01-01\"\n",
    "to_=\"2022-01-31\"\n",
    "# Medios de prensa - Region X\n",
    "media_outlets=[\"elllanquihue\",\"elaustral\",\"laestrelladechiloe\",\"elheraldoaustral\",\"radiosago\",\n",
    "               \"elrepuertero\",\"elvacanudo\",\"elhuemul\",\"seminariolocal\",\"elquellonino\",\"elinsular\",\n",
    "               \"radiopudeto\",\"radioacogida\",\"elcalbucano\",\"segundos33\",\n",
    "               \"prensadelestuario\",\"fresiaahora\",\"soychiloe\"]\n",
    "\n",
    "# Búsqueda de palabra clave\n",
    "# keyword=\"pobreza\"\n",
    "# simple_keyword=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Connection ---\n",
    "IP = \"search.sophia2.org\"\n",
    "PORT = 9200\n",
    "USER= \"elastic\"\n",
    "PASS= password\n",
    "\n",
    "# --- Connection ---\n",
    "es = elasticsearch.Elasticsearch(\n",
    "    IP,\n",
    "    http_auth=(USER, PASS)\n",
    ")\n",
    "\n",
    "# --- Queries ---\n",
    "query = { \n",
    "    \"bool\": { \n",
    "    \"filter\": [\n",
    "        {\"range\": {\n",
    "      \"date\": {\n",
    "        \"gte\": from_,\n",
    "        \"lt\": to_\n",
    "      }\n",
    "      }},\n",
    "\n",
    "        { \"term\":  { \"country\": country }},\n",
    "        { \"terms\":  { \"media_outlet\": media_outlets }} \n",
    "    ]\n",
    "    }  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Son 1311 noticias encontradas...\n"
     ]
    }
   ],
   "source": [
    "# --- Confirmación de conexión ---\n",
    "res = es.search(index=\"news\", query=query, size=10000)\n",
    "print(\"Son %d noticias encontradas...\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Columnas Dataframe ---\n",
    "data = {'id_news':[],'country':[],'media_outlet':[],'url':[],'title':[],'text':[],'date':[]}\n",
    "df = pd.DataFrame(data)  \n",
    "\n",
    "# --- Información Dataframe---\n",
    "for hit in res['hits']['hits']:\n",
    "\n",
    "    id_news = hit['_source']['id_news']\n",
    "    country = hit['_source']['country']\n",
    "    media_outlet = hit['_source']['media_outlet']\n",
    "    url = hit['_source']['url']\n",
    "    title = hit['_source']['title']\n",
    "    text = hit['_source']['text']\n",
    "    date = hit['_source']['date']\n",
    "    \n",
    "    new_row = {'id_news':int(id_news), 'country':country, 'media_outlet':media_outlet, 'url':url, 'title':title, 'text':text, 'date':date}\n",
    "    df = pd.concat([df, pd.DataFrame.from_records([new_row])])\n",
    "    # df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "\n",
    "# Reseteamos el índice del dataframe para que sea secuencial, sino serían puros 0.\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# --- Elimina resiuduos ---\n",
    "# Elimina duplicados\n",
    "df = df.drop_duplicates(subset='url', keep='first')\n",
    "# Elimina textos vacíos o con muy poco contenido\n",
    "df = df[df['text'].str.len() > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Son 1274 noticias encontradas que se utilizarán\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_news</th>\n",
       "      <th>country</th>\n",
       "      <th>media_outlet</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21907946.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>radiosago</td>\n",
       "      <td>https://www.radiosago.cl/investigan-muerte-de-...</td>\n",
       "      <td>Investigan muerte de hombre apuñalado en Máfil...</td>\n",
       "      <td>La Fiscalía de Los Lagos dirige una investigac...</td>\n",
       "      <td>2022-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21908053.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>radiosago</td>\n",
       "      <td>https://www.radiosago.cl/ante-retroceso-a-fase...</td>\n",
       "      <td>Ante retroceso a Fase 3: Municipalidad de Puye...</td>\n",
       "      <td>Frente al alza de contagios de Covid-19 en la ...</td>\n",
       "      <td>2022-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21908070.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>radiosago</td>\n",
       "      <td>https://www.radiosago.cl/alcaldesa-de-puyehue-...</td>\n",
       "      <td>Alcaldesa de Puyehue dio positivo por covid-19</td>\n",
       "      <td>La jefa comunal de la comuna lacustre, María J...</td>\n",
       "      <td>2022-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21908071.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>radiosago</td>\n",
       "      <td>https://www.radiosago.cl/el-primer-semestre-de...</td>\n",
       "      <td>El primer semestre de este año entrará en func...</td>\n",
       "      <td>La jefa de la División de Atención Primaria de...</td>\n",
       "      <td>2022-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21908072.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>radiosago</td>\n",
       "      <td>https://www.radiosago.cl/organizaciones-de-la-...</td>\n",
       "      <td>Organizaciones de la región de Los Lagos crean...</td>\n",
       "      <td>Como una necesidad por plantear la urgencia qu...</td>\n",
       "      <td>2022-01-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_news country media_outlet  \\\n",
       "0  21907946.0   chile    radiosago   \n",
       "1  21908053.0   chile    radiosago   \n",
       "2  21908070.0   chile    radiosago   \n",
       "3  21908071.0   chile    radiosago   \n",
       "4  21908072.0   chile    radiosago   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.radiosago.cl/investigan-muerte-de-...   \n",
       "1  https://www.radiosago.cl/ante-retroceso-a-fase...   \n",
       "2  https://www.radiosago.cl/alcaldesa-de-puyehue-...   \n",
       "3  https://www.radiosago.cl/el-primer-semestre-de...   \n",
       "4  https://www.radiosago.cl/organizaciones-de-la-...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Investigan muerte de hombre apuñalado en Máfil...   \n",
       "1  Ante retroceso a Fase 3: Municipalidad de Puye...   \n",
       "2     Alcaldesa de Puyehue dio positivo por covid-19   \n",
       "3  El primer semestre de este año entrará en func...   \n",
       "4  Organizaciones de la región de Los Lagos crean...   \n",
       "\n",
       "                                                text        date  \n",
       "0  La Fiscalía de Los Lagos dirige una investigac...  2022-01-26  \n",
       "1  Frente al alza de contagios de Covid-19 en la ...  2022-01-24  \n",
       "2  La jefa comunal de la comuna lacustre, María J...  2022-01-23  \n",
       "3  La jefa de la División de Atención Primaria de...  2022-01-23  \n",
       "4  Como una necesidad por plantear la urgencia qu...  2022-01-24  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Son {len(df)} noticias encontradas que se utilizarán\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadiremos las comunas mencionadas en las noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Creamos Matcher utilizando nlp ( natural language processing ) ---\n",
    "matcher_comunas = PhraseMatcher(nlp.vocab)\n",
    "for comuna in comunas:\n",
    "    matcher_comunas.add(comuna, [nlp(comuna)])\n",
    "\n",
    "# --- Función para buscar comunas ---\n",
    "for index,row in df.iterrows():\n",
    "    txt = row[\"text\"]\n",
    "    \n",
    "    try:\n",
    "        # -- Procesamos el texto --\n",
    "        doc = nlp(txt)\n",
    "        matches_comunas = matcher_comunas(doc)\n",
    "\n",
    "        # -- Creamos lista de comunas --\n",
    "        for match_id, start, end in matches_comunas:\n",
    "            span = doc[start:end]  # The matched span\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reemplazamos los espacios por guiones bajos, para cada Comuna ---\n",
    "# ejemplo: \"San Juan de la Costa\" -> \"San_Juan_de_la_Costa\"\n",
    "df_comunas = df\n",
    "for comuna in comunas:\n",
    "    df_comunas.insert(7,comuna.replace(\" \",\"_\"),0)\n",
    "\n",
    "# --- Insertamos las comunas al dataframe (df) ---\n",
    "for index,row in df_comunas.iterrows():\n",
    "    txt = row[\"text\"]\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        doc = nlp(txt)\n",
    "        matches_comunas = matcher_comunas(doc)\n",
    "\n",
    "        for match_id, start, end in matches_comunas:\n",
    "            span = doc[start:end]  # The matched span\n",
    "            df_comunas.at[index,span.text.replace(\" \",\"_\")]=1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos la información CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo se llama:\n",
      "data_Region_X_2022-01-01_2022-01-31.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Info Archivo ---\n",
    "nombre_archivo= nombre_archivo+\"_\"+from_+\"_\"+to_+\".csv\"\n",
    "print(\"El archivo se llama:\")\n",
    "print(nombre_archivo)\n",
    "\n",
    "# --- Guarda archivo ---\n",
    "df_comunas.to_csv(\"./data/\"nombre_archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Con esto tenemos toda la información necesaria para cargar los datos y utilizarlos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dff3029cfd092013fe8f81aa1ceb1e4b66244b0efa81f52c02e02255cbfd4d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
