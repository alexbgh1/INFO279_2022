{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto (obtención dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- General ---\n",
    "import os\n",
    "\n",
    "# --- Data ---\n",
    "import pandas as pd\n",
    "# from pandasql import sqldf\n",
    "# import numpy as np\n",
    "# import statistics as stats\n",
    "\n",
    "# --- Conexión ---\n",
    "import elasticsearch\n",
    "\n",
    "# --- Procesamiento lenguaje: spacy ---\n",
    "import spacy\n",
    "# from spacy.matcher import Matcher\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# --- Procesamiento lenguaje: gensim ---\n",
    "# import gensim\n",
    "# import gensim.corpora as corpora\n",
    "# from gensim.models import CoherenceModel\n",
    "\n",
    "# --- Prediccion Positividad: POS, NEU, NEG ---\n",
    "# from tqdm import tqdm\n",
    "# import transformers\n",
    "# from transformers import pipeline\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# --- Visualización ---\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim_models \n",
    "# import matplotlib.colors as colors\n",
    "# import matplotlib.pyplot as plt\n",
    "# import geopandas as gpd\n",
    "# %matplotlib inline\n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Configuración ---\n",
    "# User password\n",
    "password = os.environ.get('SOPHIA2')\n",
    "\n",
    "# - - - geoData - - -\n",
    "import tools_region as tr\n",
    "\n",
    "# --- Funciones ---\n",
    "# Cargar paquete de español mediano\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilización de regiones y comunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region encontrada\n"
     ]
    }
   ],
   "source": [
    "data_regiones_comunas = tr.search_region('Región_de_Los_Lagos')\n",
    "if(data_regiones_comunas):\n",
    "    region = data_regiones_comunas['region']\n",
    "    comunas_sql = data_regiones_comunas['comunas']\n",
    "    comunas = [comuna.replace('_', ' ') for comuna in comunas_sql]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización peticiones Sophia2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_Region_X_EMPLEO_\n"
     ]
    }
   ],
   "source": [
    "# --- [Parametros de búsqueda] ---\n",
    "# Búsqueda de palabra clave\n",
    "keyword=\"empleo empleos trabajo trabajos empleabilidad contratación\"\n",
    "simple_keyword= True\n",
    "\n",
    "# -- Nombre archivo --\n",
    "nombre_archivo = 'data_Region_X_EMPLEO_' # Resultado: ./data/{nombre_archivo}_EMPLEO_{from_}_{to_}.csv\n",
    "\n",
    "# -- Parameters queries --\n",
    "# País\n",
    "country=\"chile\"\n",
    "# Fecha\n",
    "from_=\"2022-01-01\"\n",
    "to_=\"2022-06-30\"\n",
    "# Medios de prensa - Region X\n",
    "media_outlets=[\"elllanquihue\",\"elaustral\",\"laestrelladechiloe\",\"elheraldoaustral\",\"radiosago\",\n",
    "               \"elrepuertero\",\"elvacanudo\",\"elhuemul\",\"seminariolocal\",\"elquellonino\",\"elinsular\",\n",
    "               \"radiopudeto\",\"radioacogida\",\"elcalbucano\",\"segundos33\",\n",
    "               \"prensadelestuario\",\"fresiaahora\",\"soychiloe\"]\n",
    "\n",
    "print(nombre_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Connection ---\n",
    "IP = \"search.sophia2.org\"\n",
    "PORT = 9200\n",
    "USER= \"elastic\"\n",
    "PASS=  password\n",
    "\n",
    "# --- Connection ---\n",
    "es = elasticsearch.Elasticsearch(\n",
    "    IP,\n",
    "    http_auth=(USER, PASS)\n",
    ")\n",
    "\n",
    "# --- keyword is phrase or just words---\n",
    "\n",
    "match=\"\"\n",
    "if (simple_keyword):\n",
    "    match=\"match\"\n",
    "else:\n",
    "    match=\"match_phrase\"\n",
    "\n",
    "# --- Queries ---\n",
    "query = { \n",
    "    \"bool\": { \n",
    "     \"must\": [\n",
    "        {match: { \"text\":keyword}}\n",
    "\n",
    "      ],\n",
    "    \"filter\": [\n",
    "        {\"range\": {\n",
    "      \"date\": {\n",
    "        \"gte\": from_,\n",
    "        \"lt\": to_\n",
    "      }\n",
    "      }},\n",
    "\n",
    "        { \"term\":  { \"country\": country }},\n",
    "        { \"terms\":  { \"media_outlet\": media_outlets }} \n",
    "    ]\n",
    "    }  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Son 1652 noticias encontradas...\n"
     ]
    }
   ],
   "source": [
    "# --- Confirmación de conexión ---\n",
    "res = es.search(index=\"news\", query=query, size=10000)\n",
    "print(\"Son %d noticias encontradas...\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Columnas Dataframe ---\n",
    "data = {'id_news':[],'country':[],'media_outlet':[],'url':[],'title':[],'text':[],'date':[]}\n",
    "df = pd.DataFrame(data)  \n",
    "\n",
    "# --- Información Dataframe---\n",
    "for hit in res['hits']['hits']:\n",
    "\n",
    "    id_news = hit['_source']['id_news']\n",
    "    country = hit['_source']['country']\n",
    "    media_outlet = hit['_source']['media_outlet']\n",
    "    url = hit['_source']['url']\n",
    "    title = hit['_source']['title']\n",
    "    text = hit['_source']['text']\n",
    "    date = hit['_source']['date']\n",
    "    \n",
    "    new_row = {'id_news':int(id_news), 'country':country, 'media_outlet':media_outlet, 'url':url, 'title':title, 'text':text, 'date':date}\n",
    "    df = pd.concat([df, pd.DataFrame.from_records([new_row])])\n",
    "    # df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "\n",
    "# Reseteamos el índice del dataframe para que sea secuencial, sino serían puros 0.\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# --- Elimina resiuduos ---\n",
    "# Elimina duplicados\n",
    "df = df.drop_duplicates(subset='url', keep='first')\n",
    "# Elimina textos vacíos o con muy poco contenido\n",
    "df = df[df['text'].str.len() > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Son 1642 noticias encontradas que se utilizarán\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_news</th>\n",
       "      <th>country</th>\n",
       "      <th>media_outlet</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47316734.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>seminariolocal</td>\n",
       "      <td>https://www.semanariolocal.cl/archivos/6420</td>\n",
       "      <td>Parlamentario pide incentivar contratación de ...</td>\n",
       "      <td>Un aumento de mercados laborales poco dispuest...</td>\n",
       "      <td>2022-06-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22598469.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>elllanquihue</td>\n",
       "      <td>https://www.ellanquihue.cl/impresa/2022/05/03/...</td>\n",
       "      <td>En medio de inestabilidad económica preocupa p...</td>\n",
       "      <td>Casi 415 mil personas estaban empleadas, en pr...</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47315857.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>seminariolocal</td>\n",
       "      <td>https://www.semanariolocal.cl/archivos/6842</td>\n",
       "      <td>Solicitan extender IFE Laboral en mujeres para...</td>\n",
       "      <td>Luego que el Instituto Nacional de Estadística...</td>\n",
       "      <td>2022-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47587124.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>radiosago</td>\n",
       "      <td>https://www.radiosago.cl/tasa-de-desocupacion-...</td>\n",
       "      <td>Tasa de desocupación en la región de Los Lagos...</td>\n",
       "      <td>Según la Encuesta Nacional de Empleo (ENE), qu...</td>\n",
       "      <td>2022-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22598388.0</td>\n",
       "      <td>chile</td>\n",
       "      <td>radioacogida</td>\n",
       "      <td>https://radioacogida.cl/sence-afianza-trabajo-...</td>\n",
       "      <td>SENCE AFIANZA TRABAJO CON OFICINAS OMIL DE LA ...</td>\n",
       "      <td>En San Pablo, provincia de Osorno y en Chonchi...</td>\n",
       "      <td>2022-05-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_news country    media_outlet  \\\n",
       "0  47316734.0   chile  seminariolocal   \n",
       "1  22598469.0   chile    elllanquihue   \n",
       "2  47315857.0   chile  seminariolocal   \n",
       "3  47587124.0   chile       radiosago   \n",
       "4  22598388.0   chile    radioacogida   \n",
       "\n",
       "                                                 url  \\\n",
       "0        https://www.semanariolocal.cl/archivos/6420   \n",
       "1  https://www.ellanquihue.cl/impresa/2022/05/03/...   \n",
       "2        https://www.semanariolocal.cl/archivos/6842   \n",
       "3  https://www.radiosago.cl/tasa-de-desocupacion-...   \n",
       "4  https://radioacogida.cl/sence-afianza-trabajo-...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Parlamentario pide incentivar contratación de ...   \n",
       "1  En medio de inestabilidad económica preocupa p...   \n",
       "2  Solicitan extender IFE Laboral en mujeres para...   \n",
       "3  Tasa de desocupación en la región de Los Lagos...   \n",
       "4  SENCE AFIANZA TRABAJO CON OFICINAS OMIL DE LA ...   \n",
       "\n",
       "                                                text        date  \n",
       "0  Un aumento de mercados laborales poco dispuest...  2022-06-06  \n",
       "1  Casi 415 mil personas estaban empleadas, en pr...  2022-05-03  \n",
       "2  Luego que el Instituto Nacional de Estadística...  2022-06-29  \n",
       "3  Según la Encuesta Nacional de Empleo (ENE), qu...  2022-05-30  \n",
       "4  En San Pablo, provincia de Osorno y en Chonchi...  2022-05-11  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Son {len(df)} noticias encontradas que se utilizarán\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos las noticias sin menciones a comunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Guarda archivo ---\n",
    "# print(nombre_archivo+from_+\"_\"+to_+'.csv')\n",
    "# df.to_csv(\"./data/\"+nombre_archivo+from_+\"_\"+to_+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadiremos las comunas mencionadas en las noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Creamos Matcher utilizando nlp ( natural language processing ) ---\n",
    "matcher_comunas = PhraseMatcher(nlp.vocab)\n",
    "for comuna in comunas:\n",
    "    matcher_comunas.add(comuna, [nlp(comuna)])\n",
    "\n",
    "# --- Función para buscar comunas ---\n",
    "for index,row in df.iterrows():\n",
    "    txt = row[\"text\"]\n",
    "    \n",
    "    try:\n",
    "        # -- Procesamos el texto --\n",
    "        doc = nlp(txt)\n",
    "        matches_comunas = matcher_comunas(doc)\n",
    "\n",
    "        # -- Creamos lista de comunas --\n",
    "        for match_id, start, end in matches_comunas:\n",
    "            span = doc[start:end]  # The matched span\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reemplazamos los espacios por guiones bajos, para cada Comuna ---\n",
    "# ejemplo: \"San Juan de la Costa\" -> \"San_Juan_de_la_Costa\"\n",
    "df_comunas = df\n",
    "for comuna in comunas:\n",
    "    df_comunas.insert(7,comuna.replace(\" \",\"_\"),0)\n",
    "\n",
    "# --- Insertamos las comunas al dataframe (df) ---\n",
    "for index,row in df_comunas.iterrows():\n",
    "    txt = row[\"text\"]\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        doc = nlp(txt)\n",
    "        matches_comunas = matcher_comunas(doc)\n",
    "\n",
    "        for match_id, start, end in matches_comunas:\n",
    "            span = doc[start:end]  # The matched span\n",
    "            df_comunas.at[index,span.text.replace(\" \",\"_\")]=1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos la información CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_Region_X_EMPLEO_comunas_2022-01-01_2022-06-30.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Guarda archivo ---\n",
    "print(nombre_archivo+'comunas_'+from_+\"_\"+to_+\".csv\")\n",
    "df_comunas.to_csv(\"./data/\"+nombre_archivo+'comunas_'+from_+\"_\"+to_+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Con esto tenemos toda la información necesaria para cargar los datos y utilizarlos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fff480b818351191bd10b139918affcc268b35a4173b95bc67c9e000e77644a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
